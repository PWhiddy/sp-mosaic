{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b345dfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81044499",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "924756ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import clip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1bc1aa",
   "metadata": {},
   "source": [
    "## Functional Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0de116a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functional version of code above\n",
    "def create_mosaic(all_img_paths, dim, pre_crop, img_size, out_name):\n",
    "    model, preprocess = clip.load('ViT-B/32')\n",
    "    embeddings = torch.zeros(len(all_img_paths), 512)\n",
    "    print(\"Generating clip embeddings\")\n",
    "    with torch.no_grad():\n",
    "        for idx, p in tqdm(list(enumerate(all_img_paths))):\n",
    "            img = preprocess(Image.open(p)).unsqueeze(0)\n",
    "            embeddings[idx] = model.encode_image(img).squeeze()\n",
    "    X = embeddings.numpy()\n",
    "    pca = PCA(n_components=2)\n",
    "    pca_vals = pca.fit_transform(X)\n",
    "    print(f\"Explained variance by first 2 principal components: {pca.explained_variance_ratio_.sum()}\")\n",
    "    comps_with_idx = [{\"img_idx\": idx, \"comps\": comps } for idx, comps in enumerate(pca_vals)]\n",
    "    print(\"Sorting grid\")\n",
    "    # sort x \n",
    "    x_sorted = sorted(comps_with_idx, key=lambda comps: comps[\"comps\"][0])\n",
    "    grid_sorted = []\n",
    "    for i in range(dim):\n",
    "        row = x_sorted[i*dim:(i+1)*dim]\n",
    "        row_sorted = sorted(row, key=lambda comps: comps[\"comps\"][1])\n",
    "        grid_sorted.append(row_sorted)\n",
    "    crop_amt = (pre_crop - img_size) / 2\n",
    "    total_dim = dim*img_size\n",
    "    main_img = np.zeros((total_dim,total_dim,4), dtype=np.uint8)\n",
    "    print(\"Creating Tiles\")\n",
    "    for y_idx, row in tqdm(list(enumerate(grid_sorted))):\n",
    "        for x_idx, comps in enumerate(row):\n",
    "            img_idx = comps[\"img_idx\"]\n",
    "            img = Image.open(all_img_paths[img_idx])\n",
    "            resized_img = img.resize((pre_crop, pre_crop))\n",
    "            if (resized_img.mode != \"RGBA\"):\n",
    "                # replace pixels matching alpha_val with transparency\n",
    "                new_img = np.ones((pre_crop,pre_crop,4), dtype=np.uint8)*255\n",
    "                new_img[:,:,:3] = resized_img\n",
    "                # from https://github.com/PWhiddy/PokemonRedExperiments/blob/master/MapWalkingVis.ipynb\n",
    "                alpha_val = np.array([255, 255,  255, 255], dtype=np.uint8)\n",
    "                alpha_mask = (new_img == alpha_val).all(axis=2).reshape(pre_crop,pre_crop,1)\n",
    "                resized_img = Image.fromarray( np.where(alpha_mask, np.array([[[0,0,0,0]]]), new_img).astype(np.uint8) )\n",
    "            cropped_img = resized_img.crop((crop_amt,crop_amt,pre_crop-crop_amt, pre_crop-crop_amt))\n",
    "            main_img[\n",
    "                x_idx*img_size:(x_idx+1)*img_size, \n",
    "                y_idx*img_size:(y_idx+1)*img_size] = np.asarray(cropped_img)\n",
    "    im = Image.fromarray(main_img)\n",
    "    im.save(out_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80df8b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = Path(\"shader-park-core.appspot.com/sculptureThumbnails\")\n",
    "all_test_paths = list(test_path.glob(\"*.png\"))\n",
    "create_mosaic(all_test_paths, 25, 512, 256, \"test_out.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b049810",
   "metadata": {},
   "source": [
    "## Below is original implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45b9283e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 338M/338M [00:14<00:00, 24.8MiB/s]\n"
     ]
    }
   ],
   "source": [
    "model, preprocess = clip.load('ViT-B/32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3a886c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34msculptureThumbnails\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "!ls shader-park-core.appspot.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd31f6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(\"shader-park-core.appspot.com/sculptureThumbnails\")\n",
    "all_paths = list(path.glob(\"*.jpeg\")) + list(path.glob(\"*.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "52167b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = torch.zeros(len(all_paths), 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6f5beb1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1125it [01:08, 16.50it/s]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for idx, p in tqdm(enumerate(all_paths)):\n",
    "        img = preprocess(Image.open(p)).unsqueeze(0)\n",
    "        embeddings[idx] = model.encode_image(img).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "60f3425e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16663381\n"
     ]
    }
   ],
   "source": [
    "X = embeddings.numpy()\n",
    "pca = PCA(n_components=2)\n",
    "#pca.fit(X)\n",
    "pca_vals = pca.fit_transform(X)\n",
    "print(pca.explained_variance_ratio_.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "62e99565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1125, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.3595157 , -1.2727263 ],\n",
       "       [-0.6688118 , -0.9418027 ],\n",
       "       [ 0.60495144, -0.85944796],\n",
       "       [ 0.29132822, -0.8286504 ]], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(pca_vals.shape)\n",
    "pca_vals[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e83b69c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "comps_with_idx = [{\"img_idx\": idx, \"comps\": comps } for idx, comps in enumerate(pca_vals)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "22348b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# sort x \n",
    "x_sorted = sorted(comps_with_idx, key=lambda comps: comps[\"comps\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c655a341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort y\n",
    "dim = 34\n",
    "grid_sorted = []\n",
    "for i in range(dim):\n",
    "    row = x_sorted[i*dim:(i+1)*dim]\n",
    "    row_sorted = sorted(row, key=lambda comps: comps[\"comps\"][1])\n",
    "    grid_sorted.append(row_sorted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c59cb2d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "34it [00:38,  1.14s/it]\n"
     ]
    }
   ],
   "source": [
    "# clip sorted version \n",
    "\n",
    "dim = 34\n",
    "pre_crop = 512\n",
    "img_size = 256\n",
    "crop_amt = (pre_crop - img_size) / 2\n",
    "total_dim = dim*img_size\n",
    "main_img = np.zeros((total_dim,total_dim,4), dtype=np.uint8)\n",
    "for y_idx, row in tqdm(enumerate(grid_sorted)):\n",
    "    for x_idx, comps in enumerate(row):\n",
    "        img_idx = comps[\"img_idx\"]\n",
    "        img = Image.open(all_paths[img_idx])\n",
    "        resized_img = img.resize((pre_crop, pre_crop))\n",
    "        if (resized_img.mode != \"RGBA\"):\n",
    "            new_img = np.ones((pre_crop,pre_crop,4), dtype=np.uint8)*255\n",
    "            new_img[:,:,:3] = resized_img\n",
    "            # from https://github.com/PWhiddy/PokemonRedExperiments/blob/master/MapWalkingVis.ipynb\n",
    "            alpha_val = np.array([255, 255,  255, 255], dtype=np.uint8)\n",
    "            alpha_mask = (new_img == alpha_val).all(axis=2).reshape(pre_crop,pre_crop,1)\n",
    "            resized_img = Image.fromarray( np.where(alpha_mask, np.array([[[0,0,0,0]]]), new_img).astype(np.uint8) )\n",
    "        #print((crop_amt,pre_crop-crop_amt,pre_crop-crop_amt, crop_amt))\n",
    "        # left, top, right, bottom\n",
    "        cropped_img = resized_img.crop((crop_amt,crop_amt,pre_crop-crop_amt, pre_crop-crop_amt))\n",
    "        main_img[\n",
    "            x_idx*img_size:(x_idx+1)*img_size, \n",
    "            y_idx*img_size:(y_idx+1)*img_size] = np.asarray(cropped_img)\n",
    "im = Image.fromarray(main_img)\n",
    "im.save(\"grid_full_sorted_crop.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "eab51a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1125/1125 [00:40<00:00, 28.10it/s]\n"
     ]
    }
   ],
   "source": [
    "# full version\n",
    "dim = 34\n",
    "img_size = 512\n",
    "total_dim = dim*img_size\n",
    "main_img = np.zeros((total_dim,total_dim,4), dtype=np.uint8)\n",
    "x_idx = 0\n",
    "y_idx = 0\n",
    "all_paths = list(path.glob(\"*.jpeg\")) + list(path.glob(\"*.png\"))\n",
    "for p in tqdm(all_paths):\n",
    "    img = Image.open(p)\n",
    "    resized_img = img.resize((img_size, img_size))\n",
    "    if (resized_img.mode != \"RGBA\"):\n",
    "        new_img = np.ones((img_size,img_size,4), dtype=np.uint8)*255\n",
    "        new_img[:,:,:3] = resized_img\n",
    "        # from https://github.com/PWhiddy/PokemonRedExperiments/blob/master/MapWalkingVis.ipynb\n",
    "        alpha_val = np.array([255, 255,  255, 255], dtype=np.uint8)\n",
    "        alpha_mask = (new_img == alpha_val).all(axis=2).reshape(img_size,img_size,1)\n",
    "        resized_img = np.where(alpha_mask, np.array([[[0,0,0,0]]]), new_img)\n",
    "    main_img[\n",
    "        x_idx*img_size:(x_idx+1)*img_size, \n",
    "        y_idx*img_size:(y_idx+1)*img_size] = np.asarray(resized_img)\n",
    "    x_idx += 1\n",
    "    if x_idx >= dim:\n",
    "        x_idx = 0\n",
    "        y_idx += 1\n",
    "im = Image.fromarray(main_img)\n",
    "im.save(\"grid_full.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "73692028",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17408"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "70c289cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1125/1125 [00:38<00:00, 28.90it/s]\n"
     ]
    }
   ],
   "source": [
    "# cropped version\n",
    "dim = 34\n",
    "pre_crop = 512\n",
    "img_size = 256\n",
    "crop_amt = (pre_crop - img_size) / 2\n",
    "total_dim = dim*img_size\n",
    "main_img = np.zeros((total_dim,total_dim,4), dtype=np.uint8)\n",
    "x_idx = 0\n",
    "y_idx = 0\n",
    "all_paths = list(path.glob(\"*.jpeg\")) + list(path.glob(\"*.png\"))\n",
    "#all_paths = all_paths[:20]\n",
    "for p in tqdm(all_paths):\n",
    "    img = Image.open(p)\n",
    "    resized_img = img.resize((pre_crop, pre_crop))\n",
    "    if (resized_img.mode != \"RGBA\"):\n",
    "        new_img = np.ones((pre_crop,pre_crop,4), dtype=np.uint8)*255\n",
    "        new_img[:,:,:3] = resized_img\n",
    "        # from https://github.com/PWhiddy/PokemonRedExperiments/blob/master/MapWalkingVis.ipynb\n",
    "        alpha_val = np.array([255, 255,  255, 255], dtype=np.uint8)\n",
    "        alpha_mask = (new_img == alpha_val).all(axis=2).reshape(pre_crop,pre_crop,1)\n",
    "        resized_img = Image.fromarray( np.where(alpha_mask, np.array([[[0,0,0,0]]]), new_img).astype(np.uint8) )\n",
    "    #print((crop_amt,pre_crop-crop_amt,pre_crop-crop_amt, crop_amt))\n",
    "    # left, top, right, bottom\n",
    "    cropped_img = resized_img.crop((crop_amt,crop_amt,pre_crop-crop_amt, pre_crop-crop_amt))\n",
    "    main_img[\n",
    "        x_idx*img_size:(x_idx+1)*img_size, \n",
    "        y_idx*img_size:(y_idx+1)*img_size] = np.asarray(cropped_img)\n",
    "    x_idx += 1\n",
    "    if x_idx >= dim:\n",
    "        x_idx = 0\n",
    "        y_idx += 1\n",
    "im = Image.fromarray(main_img)\n",
    "im.save(\"grid_cropped.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50025e4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d10e703",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92d01ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
